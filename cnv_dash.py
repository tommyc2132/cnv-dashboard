# cnv_dash.py
import os
import calendar
from datetime import date

import pandas as pd
import streamlit as st

from google.cloud import bigquery
from google.oauth2 import service_account

# =========================================================
# 0) ê³ ì • ì„¤ì •
# =========================================================
PROJECT_ID = os.environ.get("PROJECT_ID", "strange-reducer-474905-g1").strip()

DEFAULT_TABLE_FQN = f"{PROJECT_ID}.streamlit.cnv_dash_tbl"
SOURCE_FQN = os.environ.get("CNV_SOURCE", DEFAULT_TABLE_FQN).strip()

GOOGLE_KEY_PATH = os.environ.get(
    "GOOGLE_KEY_PATH",
    r"C:\tommy\BigQuery\strange-reducer-474905-g1-946a9f4f9fac.json"
).strip()

BQ_LOCATION = os.environ.get("BQ_LOCATION", "asia-northeast3").strip()

# =========================================================
# 1) Streamlit ê¸°ë³¸
# =========================================================
st.set_page_config(page_title="ìƒë‹´ â†’ ì£¼ë¬¸(0~48h) ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ğŸ“Š ìƒë‹´ â†’ ì£¼ë¬¸ì „í™˜ ì¸¡ì • (0~48h) ëŒ€ì‹œë³´ë“œ ")

# ğŸ”¥ ì „í™˜ìœ¨ ì •ì˜ ë…¸í‹°
st.markdown(
    """
<div style="
  background-color:#fff4e5;
  border-left:6px solid #ff9800;
  padding:12px 14px;
  border-radius:6px;
  font-size:0.95rem;
  line-height:1.5;
">
<b>ì „í™˜ìœ¨ ì‚°ì • ê¸°ì¤€ ë³€ê²½</b><br/>
- ë³¸ ëŒ€ì‹œë³´ë“œëŠ” <b>**ë¬´íš¨ ìƒë‹´ì„ ëª¨ìˆ˜ì—ì„œ ì œì™¸**</b>í•œ í›„ ì „í™˜ìœ¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤.<br/>
- ì •ìƒ ìƒë‹´ ê¸°ì¤€ì˜ <b>ì‹¤ì§ˆ êµ¬ë§¤ ì „í™˜ ì„±ê³¼</b>ë¥¼ ë³´ê¸° ìœ„í•¨.<br/>
- ì „í™˜ ì¡°ê±´: <b>ìƒë‹´ í›„ 48ì‹œê°„ ì´ë‚´</b>, <b>Cì£¼ë¬¸ ì œì™¸</b>, <b>ê²°ì œê¸ˆì•¡ &gt; 0</b>
</div>
""",
    unsafe_allow_html=True
)

st.caption(" Â· ë‚ ì§œ ê¸°ì¤€: ìƒë‹´ì¼ì(inbound_date)")

# =========================================================
# 2) BigQuery Client (ì„œìš¸ ë¦¬ì „ ê³ ì •)
# =========================================================
@st.cache_resource(show_spinner=False)
def get_bq_client():
    # 1) ë¡œì»¬ í‚¤íŒŒì¼ ìš°ì„ 
    if GOOGLE_KEY_PATH and os.path.exists(GOOGLE_KEY_PATH):
        creds = service_account.Credentials.from_service_account_file(
            GOOGLE_KEY_PATH,
            scopes=["https://www.googleapis.com/auth/cloud-platform"],
        )
        return bigquery.Client(
            project=PROJECT_ID,
            credentials=creds,
            location=BQ_LOCATION
        )

    # 2) Secrets
    try:
        if "gcp_service_account" in st.secrets:
            info = dict(st.secrets["gcp_service_account"])
            creds = service_account.Credentials.from_service_account_info(
                info,
                scopes=["https://www.googleapis.com/auth/cloud-platform"],
            )
            return bigquery.Client(
                project=PROJECT_ID,
                credentials=creds,
                location=BQ_LOCATION
            )
    except Exception:
        pass

    # 3) ADC
    return bigquery.Client(
        project=PROJECT_ID,
        location=BQ_LOCATION
    )

# =========================================================
# 3) UI í•œê¸€ ì»¬ëŸ¼ ë§¤í•‘
# =========================================================
KOR_COL_MAP = {
    "inbound_date": "ìƒë‹´ì¼ì",
    "inbound_ts": "ìƒë‹´ì‹œì ",
    "inbound_channel": "ì¸ì…ì±„ë„",
    "ticket_id": "í‹°ì¼“ë²ˆí˜¸",
    "agent_center": "ì„¼í„°ëª…",
    "agent_name": "ë‹´ë‹¹ì",
    "brand_name": "ìƒë‹´ë¸Œëœë“œ",
    "matched_brand": "ì£¼ë¬¸ë¸Œëœë“œ",
    "category_lv1": "ë¬¸ì˜ìœ í˜•_ëŒ€",
    "category_lv2": "ë¬¸ì˜ìœ í˜•_ì¤‘",
    "category_lv3": "ë¬¸ì˜ìœ í˜•_ì†Œ",
    "customer_phone": "ê³ ê°íœ´ëŒ€í°",
    "converted_yn": "ì „í™˜ì—¬ë¶€",
    "first_order_ts": "ì£¼ë¬¸ì‹œì ",
    "order_cnt": "ì „í™˜ì£¼ë¬¸ìˆ˜",
    "order_amount": "ì£¼ë¬¸ê¸ˆì•¡",
    "min_leadtime_h": "ë¦¬ë“œíƒ€ì„",
    "order_nos": "ì „í™˜ì£¼ë¬¸ë²ˆí˜¸",
    "sellers": "íŒë§¤ì²˜",
    "matched_by": "ë§¤ì¹­ê¸°ì¤€",
    "ticket_cnt": "í‹°ì¼“ìˆ˜",
    "conv_rate": "ì „í™˜ìœ¨",
}

def apply_kor_columns(df: pd.DataFrame) -> pd.DataFrame:
    return df.rename(columns={k: v for k, v in KOR_COL_MAP.items() if k in df.columns})

# =========================================================
# 3-1) ğŸ”¥ Rank: í™”ë©´ì€ "ì–‡ê²Œ" ë³´ì´ê²Œ (indexë¡œ) / CSVëŠ” ì»¬ëŸ¼ìœ¼ë¡œ
# =========================================================
def with_rank_index(df: pd.DataFrame, index_name: str = "Rank") -> pd.DataFrame:
    out = df.copy()
    out.index = range(1, len(out) + 1)
    out.index.name = index_name
    return out

def with_rank_col(df: pd.DataFrame, col_name: str = "Rank") -> pd.DataFrame:
    out = df.copy()
    out.insert(0, col_name, range(1, len(out) + 1))
    return out

# =========================================================
# 4) ë¹„ìš© ìº¡
# =========================================================
def bytes_from_gb(gb: float) -> int:
    return int(gb * 1024 * 1024 * 1024)

# =========================================================
# 5) ê¸°ê°„ ì„ íƒ: ì›” ë“œë¡­ë‹¤ìš´(2026-01ë¶€í„°) + ìº˜ë¦°ë”(ììœ  ìˆ˜ì •)
# =========================================================
START_MONTH = date(2026, 1, 1)

def month_start_end(y: int, m: int):
    s = date(y, m, 1)
    e = date(y, m, calendar.monthrange(y, m)[1])
    return s, e

def build_month_options(start_month: date, end_month: date):
    start_idx = start_month.year * 12 + start_month.month
    end_idx = end_month.year * 12 + end_month.month
    opts = []
    for idx in range(end_idx, start_idx - 1, -1):
        y = (idx - 1) // 12
        m = (idx - 1) % 12 + 1
        opts.append(f"{y}-{m:02d}")
    return opts

today = date.today()
this_month_start = date(today.year, today.month, 1)
month_options = build_month_options(START_MONTH, this_month_start)

def on_month_change():
    sel = st.session_state["selected_month"]
    y, m = map(int, sel.split("-"))
    s, e = month_start_end(y, m)
    st.session_state["date_from"] = s
    st.session_state["date_to"] = e

if "selected_month" not in st.session_state:
    st.session_state["selected_month"] = f"{today.year}-{today.month:02d}"
if st.session_state["selected_month"] not in month_options:
    st.session_state["selected_month"] = month_options[0]

if "date_from" not in st.session_state or "date_to" not in st.session_state:
    y, m = map(int, st.session_state["selected_month"].split("-"))
    s, e = month_start_end(y, m)
    st.session_state["date_from"] = s
    st.session_state["date_to"] = e

st.sidebar.header("ê¸°ê°„ ì„ íƒ")
st.sidebar.selectbox(
    "ì›” ì„ íƒ",
    options=month_options,
    key="selected_month",
    on_change=on_month_change,
)

date_from = st.sidebar.date_input("ì‹œì‘ì¼", key="date_from")
date_to = st.sidebar.date_input("ì¢…ë£Œì¼", key="date_to")

if date_from > date_to:
    st.sidebar.error("ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ í´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

st.sidebar.markdown(
    """
<div style="
  background-color:#e7f1ff;
  border-left:6px solid #1f6feb;
  padding:10px 12px;
  border-radius:6px;
  font-size:0.9rem;
  line-height:1.4;
">
  â­ë‚ ì§œ Default ê°’ : ì´ë²ˆë‹¬<br/>
  â­ì „í™˜ìœ¨ ì •ì˜ = SUM(ì „í™˜ì£¼ë¬¸ìˆ˜) / í‹°ì¼“ìˆ˜<br/><br/>
  <b>ì‘ì—…ì: ì¡°ì˜ìš°</b>
</div>
""",
    unsafe_allow_html=True
)

st.sidebar.divider()
st.sidebar.header("í”¼ë²— ì„¤ì •")

available_dims = [
    "agent_name",
    "brand_name",
    "category_lv1", "category_lv2", "category_lv3",
    "matched_brand",
    "converted_yn",
    "matched_by",
]

rows = st.sidebar.multiselect("ROWS (ë“œë¦´ë‹¤ìš´)", options=available_dims, default=["agent_name"])

col_candidates = [c for c in available_dims if c not in set(rows)]
col = st.sidebar.selectbox("COLUMNS (ì„ íƒ)", options=["(ì—†ìŒ)"] + col_candidates, index=0)
col = None if col == "(ì—†ìŒ)" else col

min_ticket = st.sidebar.number_input("ìµœì†Œ í‹°ì¼“ìˆ˜(í•„í„°, COLUMNS ì—†ì„ ë•Œ)", min_value=0, value=0, step=10)
sort_key = st.sidebar.selectbox(
    "ì •ë ¬",
    options=["ticket_cnt", "order_cnt", "order_amount", "conv_rate"],
    index=3
)
sort_desc = st.sidebar.checkbox("ë‚´ë¦¼ì°¨ìˆœ", value=True)

st.sidebar.divider()
st.sidebar.header("BigQuery ë¹„ìš© ì•ˆì „ì¥ì¹˜")
max_gb = st.sidebar.slider("ìµœëŒ€ ìŠ¤ìº” í—ˆìš©(GB)", min_value=0.5, max_value=50.0, value=5.0, step=0.5)
max_bytes_billed = bytes_from_gb(max_gb)

raw_limit = st.sidebar.selectbox(
    "ë¡œìš°ë°ì´í„° ê¸°ë³¸ LIMIT",
    options=[1000, 5000, 20000, 50000, 100000],
    index=3
)

# =========================================================
# 6) ì§‘ê³„ ë¡œë“œ
# =========================================================
@st.cache_data(ttl=300, show_spinner=True)
def load_agg(date_from, date_to, rows, col, max_bytes_billed: int) -> pd.DataFrame:
    client = get_bq_client()

    if not rows:
        raise ValueError("ROWSëŠ” ìµœì†Œ 1ê°œ í•„ìš”")

    if col is not None and col in rows:
        col = None

    dim_fields = ["agent_center"] + rows + ([col] if col else [])
    dim_select = ",\n      ".join(dim_fields)
    dim_groupby = ", ".join(dim_fields)

    sql = f"""
    SELECT
      {dim_select},
      COUNT(1) AS ticket_cnt,
      SUM(CAST(order_cnt AS INT64)) AS order_cnt,
      SUM(CAST(order_amount AS INT64)) AS order_amount
    FROM `{SOURCE_FQN}`
    WHERE inbound_date >= @date_from
      AND inbound_date <= @date_to
    GROUP BY {dim_groupby}
    """

    job_config = bigquery.QueryJobConfig(
        query_parameters=[
            bigquery.ScalarQueryParameter("date_from", "DATE", date_from),
            bigquery.ScalarQueryParameter("date_to", "DATE", date_to),
        ],
        maximum_bytes_billed=max_bytes_billed,
    )

    df = client.query(sql, job_config=job_config, location=BQ_LOCATION).to_dataframe(create_bqstorage_client=True)
    df["conv_rate"] = df.apply(lambda r: (r["order_cnt"] / r["ticket_cnt"]) if r["ticket_cnt"] else 0.0, axis=1)
    return df

def center_summary_from_agg(agg_df: pd.DataFrame) -> pd.DataFrame:
    cs = (
        agg_df.groupby("agent_center", dropna=False)
        .agg(
            ticket_cnt=("ticket_cnt", "sum"),
            order_cnt=("order_cnt", "sum"),
            order_amount=("order_amount", "sum"),
        )
        .reset_index()
    )
    cs["conv_rate"] = cs.apply(lambda r: (r["order_cnt"] / r["ticket_cnt"]) if r["ticket_cnt"] else 0.0, axis=1)
    return cs

# =========================================================
# 7) Raw ë¡œë“œ (ë²„íŠ¼ í´ë¦­ì‹œì—ë§Œ + LIMIT)
# =========================================================
@st.cache_data(ttl=300, show_spinner=True)
def load_raw(date_from, date_to, limit_rows: int, max_bytes_billed: int) -> pd.DataFrame:
    client = get_bq_client()

    sql = f"""
    SELECT
      inbound_ts,
      inbound_date,
      request_ts,
      assigned_ts,
      ticket_id,
      inbound_channel,
      brand_name,
      matched_brand,
      agent_center,
      agent_name,
      category_lv1,
      category_lv2,
      category_lv3,
      customer_phone,
      converted_yn,
      first_order_ts,
      order_cnt,
      order_amount,
      min_leadtime_h,
      order_nos,
      sellers,
      matched_by,
      ticket_phone,
      buyer_phone,
      receiver_phone
    FROM `{SOURCE_FQN}`
    WHERE inbound_date >= @date_from
      AND inbound_date <= @date_to
    ORDER BY inbound_date, inbound_ts, ticket_id
    LIMIT @lim
    """

    job_config = bigquery.QueryJobConfig(
        query_parameters=[
            bigquery.ScalarQueryParameter("date_from", "DATE", date_from),
            bigquery.ScalarQueryParameter("date_to", "DATE", date_to),
            bigquery.ScalarQueryParameter("lim", "INT64", int(limit_rows)),
        ],
        maximum_bytes_billed=max_bytes_billed,
    )

    df = client.query(sql, job_config=job_config, location=BQ_LOCATION).to_dataframe(create_bqstorage_client=True)
    return df

# =========================================================
# 8) í‘œì‹œ í¬ë§· (ğŸ”¥ ì „í™˜ìœ¨ UIì—ì„œë§Œ %ë¡œ)
# =========================================================
def fmt_display(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()

    def _int(x):
        try:
            return f"{int(x):,}"
        except Exception:
            return x

    def _money(x):
        try:
            return f"{int(x):,}"
        except Exception:
            return x

    # âœ… 0.0697 -> 6.97% (UI í‘œì‹œë§Œ / ì†Œìˆ˜ 2ìë¦¬)
    def _rate(x):
        try:
            return f"{float(x) * 100:.2f}%"
        except Exception:
            return x

    for c in out.columns:
        if c in ["ticket_cnt", "order_cnt"]:
            out[c] = out[c].apply(_int)
        elif c == "order_amount":
            out[c] = out[c].apply(_money)
        elif c == "conv_rate":
            out[c] = out[c].apply(_rate)

    return out

# =========================================================
# 9) ì‹¤í–‰: ì§‘ê³„ ë¡œë“œ
# =========================================================
try:
    agg_df = load_agg(date_from, date_to, rows, col, max_bytes_billed)
except Exception as e:
    st.error(f"í”¼ë²— ì§‘ê³„ ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()

if agg_df.empty:
    st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ê¸°ê°„/í•„í„° í™•ì¸)")
    st.stop()

center_sum = center_summary_from_agg(agg_df)

total_ticket = int(center_sum["ticket_cnt"].sum())
total_orders = int(center_sum["order_cnt"].sum())
total_amount = int(center_sum["order_amount"].sum())
rate = (total_orders / total_ticket) if total_ticket else 0.0

k1, k2, k3, k4 = st.columns(4)
k1.metric("ì „ì²´ í‹°ì¼“", f"{total_ticket:,}")
k2.metric("ì „í™˜ ì£¼ë¬¸ìˆ˜", f"{total_orders:,}")
k3.metric("ì „í™˜ ë§¤ì¶œ", f"{total_amount:,}")
k4.metric("ì „í™˜ìœ¨", f"{rate * 100:.2f}%")

st.divider()

# =========================================================
# 10) Tabs (í”¼ë²— / ë¡œìš°ë°ì´í„°)
# =========================================================
tab_pivot, tab_raw = st.tabs(["ğŸ“Œ í”¼ë²—(ì„¼í„°/ìƒë‹´ì‚¬/ìœ í˜•)", "ğŸ§¾ ë¡œìš°ë°ì´í„° ë‹¤ìš´ë¡œë“œ(ë§¤ì¹­ ê²°ê³¼)"])

# =========================================================
# (ìš”ì²­ 2) ì¸ì…ì±„ë„ë³„ ì „í™˜ìœ¨: í”¼ë²— íƒ­ ìµœí•˜ë‹¨ ë Œë”
# =========================================================
@st.cache_data(ttl=300, show_spinner=False)
def load_channel_summary(date_from, date_to, max_bytes_billed: int) -> pd.DataFrame:
    client = get_bq_client()
    sql = f"""
    SELECT
      inbound_channel,
      COUNT(1) AS ticket_cnt,
      SUM(CAST(order_cnt AS INT64)) AS order_cnt,
      SUM(CAST(order_amount AS INT64)) AS order_amount
    FROM `{SOURCE_FQN}`
    WHERE inbound_date BETWEEN @date_from AND @date_to
    GROUP BY inbound_channel
    """
    job_cfg = bigquery.QueryJobConfig(
        query_parameters=[
            bigquery.ScalarQueryParameter("date_from", "DATE", date_from),
            bigquery.ScalarQueryParameter("date_to", "DATE", date_to),
        ],
        maximum_bytes_billed=max_bytes_billed,
    )
    df = client.query(sql, job_config=job_cfg, location=BQ_LOCATION).to_dataframe(create_bqstorage_client=True)
    df["inbound_channel"] = df["inbound_channel"].fillna("ì—†ìŒ")
    df["conv_rate"] = df.apply(
        lambda r: (r["order_cnt"] / r["ticket_cnt"]) if r["ticket_cnt"] else 0.0,
        axis=1
    )
    return df

with tab_pivot:
    st.subheader("ì„¼í„° ìš”ì•½(ì†Œê³„)")
    center_sum_sorted = center_sum.sort_values(sort_key, ascending=not sort_desc)

    # âœ… í™”ë©´: Rankë¥¼ indexë¡œ(í­ ì–‡ê²Œ)
    center_ui_view = with_rank_index(center_sum_sorted)
    st.dataframe(
        apply_kor_columns(fmt_display(center_ui_view)),
        use_container_width=True,
        height=220,
        hide_index=False  # Rank index í‘œì‹œ(í­ ì–‡ìŒ)
    )

    # âœ… CSV: Rankë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ
    center_ui_csv = with_rank_col(center_sum_sorted)
    st.download_button(
        "ì„¼í„° ìš”ì•½ CSV ë‹¤ìš´ë¡œë“œ",
        data=apply_kor_columns(center_ui_csv).to_csv(index=False).encode("utf-8-sig"),
        file_name="center_summary.csv",
        mime="text/csv",
    )

    st.divider()
    st.subheader("ì„¼í„°ë³„ ìƒì„¸ í”¼ë²—")

    centers = center_sum_sorted["agent_center"].fillna("ì—†ìŒ").tolist()

    for center in centers:
        sub = agg_df[agg_df["agent_center"] == center].copy()

        c_ticket = int(sub["ticket_cnt"].sum())
        c_orders = int(sub["order_cnt"].sum())
        c_amount = int(sub["order_amount"].sum())
        c_rate = (c_orders / c_ticket) if c_ticket else 0.0

        header = f"{center}  |  í‹°ì¼“ {c_ticket:,} Â· ì „í™˜ì£¼ë¬¸ {c_orders:,} Â· ë§¤ì¶œ {c_amount:,} Â· ì „í™˜ìœ¨ {c_rate*100:.2f}%"
        with st.expander(header, expanded=(center in ["TCK", "SKMNS", "AI"])):

            if col is not None:
                values = ["ticket_cnt", "order_cnt", "order_amount", "conv_rate"]
                pv = sub.pivot_table(
                    index=rows,
                    columns=col,
                    values=values,
                    aggfunc="sum",
                    fill_value=0,
                )
                pv.columns = [f"{v} | {c}" for (v, c) in pv.columns]
                pv = pv.reset_index()
            else:
                keep_cols = ["agent_center"] + rows + ["ticket_cnt", "order_cnt", "order_amount", "conv_rate"]
                pv = sub[keep_cols].copy()

            if min_ticket > 0 and col is None and "ticket_cnt" in pv.columns:
                pv = pv[pv["ticket_cnt"] >= min_ticket]

            if col is None and sort_key in pv.columns:
                pv = pv.sort_values(sort_key, ascending=not sort_desc)

            # âœ… í™”ë©´: Rank indexë¡œ(í­ ì–‡ê²Œ)
            pv_view = with_rank_index(pv)
            st.dataframe(
                apply_kor_columns(fmt_display(pv_view)),
                use_container_width=True,
                height=520,
                hide_index=False
            )

            # âœ… CSV: Rank ì»¬ëŸ¼
            pv_csv = with_rank_col(pv)
            st.download_button(
                f"{center} í”¼ë²— CSV ë‹¤ìš´ë¡œë“œ",
                data=apply_kor_columns(pv_csv).to_csv(index=False).encode("utf-8-sig"),
                file_name=f"pivot_{center}.csv",
                mime="text/csv",
            )

    # =========================================================
    # í”¼ë²— íƒ­ ìµœí•˜ë‹¨: ì¸ì…ì±„ë„ë³„ ì „í™˜ìœ¨ í˜„í™©
    # =========================================================
    st.divider()
    st.subheader("ì¸ì…ì±„ë„ë³„ ì „í™˜ìœ¨ í˜„í™©")

    try:
        ch_df = load_channel_summary(date_from, date_to, max_bytes_billed)
    except Exception as e:
        st.error(f"ì¸ì…ì±„ë„ë³„ ì§‘ê³„ ë¡œë“œ ì‹¤íŒ¨: {e}")
        ch_df = pd.DataFrame()

    if ch_df.empty:
        st.info("ì¸ì…ì±„ë„ ë°ì´í„°ê°€ ì—†ê±°ë‚˜(ì»¬ëŸ¼ NULL), ê¸°ê°„ ë‚´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        if sort_key in ch_df.columns:
            ch_df = ch_df.sort_values(sort_key, ascending=not sort_desc)

        # âœ… í™”ë©´: Rank indexë¡œ(í­ ì–‡ê²Œ)
        ch_view = with_rank_index(ch_df)
        st.dataframe(
            apply_kor_columns(fmt_display(ch_view)),
            use_container_width=True,
            height=260,
            hide_index=False
        )

        # âœ… CSV: Rank ì»¬ëŸ¼
        ch_csv = with_rank_col(ch_df)
        st.download_button(
            "ì¸ì…ì±„ë„ë³„ ì „í™˜ìœ¨ CSV ë‹¤ìš´ë¡œë“œ",
            data=apply_kor_columns(ch_csv).to_csv(index=False).encode("utf-8-sig"),
            file_name="channel_conversion_summary.csv",
            mime="text/csv",
        )

with tab_raw:
    st.subheader("ë¡œìš°ë°ì´í„° (ticket+ order  ë§¤ì¹­ ê²°ê³¼ í™•ì¸ / CSV ë‹¤ìš´ë¡œë“œ)")
    st.caption(
        "âš ï¸ ë¹„ìš©/ì†ë„ ë•Œë¬¸ì— ë¡œìš°ë°ì´í„°ëŠ” **ë²„íŠ¼ì„ ëˆŒë €ì„ ë•Œë§Œ** ë¶ˆëŸ¬ì˜¤ê²Œë” ì„¸íŒ….\n"
        f"- ê¸°ë³¸ LIMIT: {raw_limit:,}\n"
        "- ê¸°ê°„ì´ ê¸¸ë©´ LIMITì„ ì˜¬ë¦¬ê¸° ì „ì— ë¨¼ì € ê¸°ê°„ì„ ì¤„ì´ëŠ” ê±¸ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.\n"
        "- ë¬¸ì˜ ì‚¬í•­ì€ ì–¸ì œë“ ì§€ ì—°ë½ ì£¼ì„¸ìš” : )"
    )

    if "raw_loaded" not in st.session_state:
        st.session_state["raw_loaded"] = False
        st.session_state["raw_df"] = None

    load_btn = st.button("ë¡œìš°ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°", type="primary")

    if load_btn:
        try:
            raw_df = load_raw(date_from, date_to, raw_limit, max_bytes_billed)
            st.session_state["raw_df"] = raw_df
            st.session_state["raw_loaded"] = True
        except Exception as e:
            st.error(f"ë¡œìš°ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            st.stop()

    if not st.session_state["raw_loaded"]:
        st.info("â¬†ï¸ ìƒë‹¨ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë¡œìš°ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì„¸ìš”.")
        st.stop()

    raw_df = st.session_state["raw_df"].copy()

    # ---- í•„í„° UI
    f1, f2, f3, f4 = st.columns(4)

    centers = sorted(raw_df["agent_center"].dropna().unique().tolist())
    agents = sorted(raw_df["agent_name"].dropna().unique().tolist())
    convs = ["O", "X"]
    matched_by_opts = sorted([x for x in raw_df["matched_by"].dropna().unique().tolist()])

    with f1:
        center_sel = st.multiselect("ì„¼í„°", options=centers, default=centers)
    with f2:
        agent_sel = st.multiselect("ë‹´ë‹¹ì", options=agents, default=agents)
    with f3:
        conv_sel = st.multiselect("ì „í™˜ì—¬ë¶€", options=convs, default=convs)
    with f4:
        matched_by_sel = st.multiselect("ë§¤ì¹­ê¸°ì¤€", options=matched_by_opts)

    q = st.text_input("ê²€ìƒ‰(í‹°ì¼“/ì£¼ë¬¸ë²ˆí˜¸/ì „í™”/ë¸Œëœë“œ)", value="").strip()

    filtered = raw_df[
        raw_df["agent_center"].isin(center_sel)
        & raw_df["agent_name"].isin(agent_sel)
        & raw_df["converted_yn"].isin(conv_sel)
    ].copy()

    if matched_by_sel:
        filtered = filtered[(filtered["matched_by"].isin(matched_by_sel)) | (filtered["converted_yn"] == "X")].copy()

    if q:
        for c in ["ticket_id", "order_nos", "customer_phone", "brand_name", "matched_brand",
                  "ticket_phone", "buyer_phone", "receiver_phone", "inbound_channel"]:
            if c in filtered.columns:
                filtered.loc[:, c] = filtered[c].astype(str)

        mask = (
            filtered["ticket_id"].str.contains(q, na=False)
            | filtered["order_nos"].str.contains(q, na=False)
            | filtered["customer_phone"].str.contains(q, na=False)
            | filtered["brand_name"].str.contains(q, na=False)
            | filtered["matched_brand"].str.contains(q, na=False)
            | filtered["ticket_phone"].str.contains(q, na=False)
            | filtered["buyer_phone"].str.contains(q, na=False)
            | filtered["receiver_phone"].str.contains(q, na=False)
            | filtered["inbound_channel"].str.contains(q, na=False)
        )
        filtered = filtered[mask].copy()

    st.write(f"ì¡°íšŒ ê²°ê³¼: {len(filtered):,} rows (LIMIT={raw_limit:,})")

    show_cols = [
        "inbound_date", "inbound_ts",
        "ticket_id", "inbound_channel", "agent_center", "agent_name",
        "brand_name", "matched_brand",
        "category_lv1", "category_lv2", "category_lv3",
        "customer_phone",
        "converted_yn",
        "first_order_ts",
        "order_cnt", "order_amount", "min_leadtime_h",
        "order_nos", "sellers",
        "matched_by",
        "ticket_phone", "buyer_phone", "receiver_phone",
    ]
    show_cols = [c for c in show_cols if c in filtered.columns]

    raw_base = filtered[show_cols].copy()

    # âœ… í™”ë©´: Rank indexë¡œ(í­ ì–‡ê²Œ)
    raw_view = with_rank_index(raw_base)
    st.dataframe(
        apply_kor_columns(raw_view),
        use_container_width=True,
        height=650,
        hide_index=False
    )

    # âœ… CSV: Rank ì»¬ëŸ¼
    raw_csv = with_rank_col(raw_base)
    st.download_button(
        "ë¡œìš°ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ(í•„í„° ë°˜ì˜)",
        data=apply_kor_columns(raw_csv).to_csv(index=False).encode("utf-8-sig"),
        file_name=f"cnv_raw_{date_from}_{date_to}_limit{raw_limit}.csv",
        mime="text/csv",
    )
