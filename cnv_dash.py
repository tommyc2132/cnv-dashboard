# cnv_dash.py
import os
import pandas as pd
import streamlit as st

from google.cloud import bigquery
from google.oauth2 import service_account

# =========================================================
# 0) ê³ ì • ì„¤ì •
# =========================================================
PROJECT_ID = os.environ.get("PROJECT_ID", "strange-reducer-474905-g1").strip()

# âœ… ê¸°ë³¸ ì†ŒìŠ¤: VIEW
DEFAULT_VIEW_FQN = f"{PROJECT_ID}.streamlit.01cnv"

# âœ… ë¹„ìš© ì ˆê°ìš©: íŒŒí‹°ì…˜ í…Œì´ë¸”ì„ ë§Œë“¤ë©´ ì—¬ê¸°ë¡œ ë°”ê¾¸ë©´ ë¨ (envë¡œë„ ê°€ëŠ¥)
# ì˜ˆ: CNV_SOURCE=strange-reducer-474905-g1.streamlit.cnv_01cnv_tbl
SOURCE_FQN = os.environ.get("CNV_SOURCE", DEFAULT_VIEW_FQN).strip()

# âœ… ë¡œì»¬ìš© í‚¤ ê²½ë¡œ(ë¡œì»¬ì—ì„œë§Œ ì“°ê³ , GitHub/ë°°í¬ì—ì„œëŠ” Secrets ë˜ëŠ” ADC ì‚¬ìš©)
GOOGLE_KEY_PATH = os.environ.get(
    "GOOGLE_KEY_PATH",
    r"C:\tommy\BigQuery\strange-reducer-474905-g1-946a9f4f9fac.json"
).strip()

# =========================================================
# 1) Streamlit ê¸°ë³¸
# =========================================================
st.set_page_config(page_title="ìƒë‹´â†’ì£¼ë¬¸(0~72h) í”¼ë²— ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ğŸ“Š ìƒë‹´ â†’ ì£¼ë¬¸(0~72h) í”¼ë²— ëŒ€ì‹œë³´ë“œ ì¡°ì˜ìš°")

# =========================================================
# 2) BigQuery Client (ë¡œì»¬/ê¹ƒ/ë°°í¬ ë²”ìš©)
# ìš°ì„ ìˆœìœ„:
#  1) ë¡œì»¬ í‚¤íŒŒì¼(GOOGLE_KEY_PATH ì¡´ì¬)  â† ë¡œì»¬ì—ì„œ ê°€ì¥ ì•ˆì •
#  2) Streamlit Secrets(st.secrets["gcp_service_account"])  â† Streamlit Cloud ì •ì„
#  3) ADC (Application Default Credentials)               â† Cloud Run/ë¡œì»¬ gcloud auth ë“±
# =========================================================
@st.cache_resource(show_spinner=False)
def get_bq_client():
    # 1) ë¡œì»¬ í‚¤íŒŒì¼ ìš°ì„ 
    if GOOGLE_KEY_PATH and os.path.exists(GOOGLE_KEY_PATH):
        creds = service_account.Credentials.from_service_account_file(
            GOOGLE_KEY_PATH,
            scopes=["https://www.googleapis.com/auth/cloud-platform"],
        )
        return bigquery.Client(project=PROJECT_ID, credentials=creds)

    # 2) Secrets (secrets.toml ì—†ìœ¼ë©´ st.secrets ì ‘ê·¼ ìì²´ê°€ ì˜ˆì™¸ì¼ ìˆ˜ ìˆìŒ â†’ ì •ìƒ fallback)
    try:
        if "gcp_service_account" in st.secrets:
            info = dict(st.secrets["gcp_service_account"])
            creds = service_account.Credentials.from_service_account_info(
                info,
                scopes=["https://www.googleapis.com/auth/cloud-platform"],
            )
            return bigquery.Client(project=PROJECT_ID, credentials=creds)
    except FileNotFoundError:
        # ë¡œì»¬ì—ì„œ secrets.toml ì—†ì„ ë•Œ ì •ìƒ
        pass
    except Exception as e:
        # secretsê°€ "ìˆëŠ”ë°" í¬ë§·ì´ ê¹¨ì§„ ê²½ìš° ë“±
        raise RuntimeError(f"Streamlit Secrets ë¡œë“œ/íŒŒì‹± ì‹¤íŒ¨: {e}")

    # 3) ADC ì‹œë„ (Cloud Run / gcloud auth application-default login ë“±)
    try:
        return bigquery.Client(project=PROJECT_ID)
    except Exception as e:
        raise FileNotFoundError(
            "BigQuery ì¸ì¦ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
            "[ë¡œì»¬]\n"
            "- GOOGLE_KEY_PATH ê²½ë¡œì˜ ì„œë¹„ìŠ¤ê³„ì • JSON íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n"
            "- ë˜ëŠ” `gcloud auth application-default login` ìœ¼ë¡œ ADC ì„¤ì •\n\n"
            "[ë°°í¬(Streamlit Cloud)]\n"
            "- Settings â†’ Secrets ì— gcp_service_account ë“±ë¡\n\n"
            f"ì›ì¸: {e}"
        )

# =========================================================
# 3) ë¹„ìš© ìº¡(ì‹¤ìˆ˜ ë°©ì§€)
# =========================================================
def bytes_from_gb(gb: float) -> int:
    return int(gb * 1024 * 1024 * 1024)

# =========================================================
# 4) Pivot ì§‘ê³„ ì¿¼ë¦¬ (ë¹„ìš© ìµœì†Œí™” í•µì‹¬)
# =========================================================
@st.cache_data(ttl=300, show_spinner=True)
def load_agg(date_from, date_to, rows, col, max_bytes_billed: int) -> pd.DataFrame:
    client = get_bq_client()

    if not rows:
        raise ValueError("ROWSëŠ” ìµœì†Œ 1ê°œ í•„ìš”")

    # colì´ rowsì— ë“¤ì–´ê°€ë©´ ì¤‘ë³µì´ë¯€ë¡œ ì œê±°
    if col is not None and col in rows:
        col = None

    dim_fields = ["agent_center"] + rows + ([col] if col else [])
    dim_select = ",\n      ".join([f"{f}" for f in dim_fields])
    dim_groupby = ", ".join(dim_fields)

    sql = f"""
    SELECT
      {dim_select},
      COUNT(1) AS ticket_cnt,
      SUM(CAST(conv_order_cnt AS INT64)) AS conv_order_cnt,
      SUM(CAST(conv_pay_amount AS INT64)) AS conv_pay_amount
    FROM `{SOURCE_FQN}`
    WHERE inbound_date_kst >= @date_from
      AND inbound_date_kst <= @date_to
    GROUP BY {dim_groupby}
    """

    job_config = bigquery.QueryJobConfig(
        query_parameters=[
            bigquery.ScalarQueryParameter("date_from", "DATE", date_from),
            bigquery.ScalarQueryParameter("date_to", "DATE", date_to),
        ],
        maximum_bytes_billed=max_bytes_billed,
    )

    df = client.query(sql, job_config=job_config).to_dataframe(create_bqstorage_client=True)

    # ì „í™˜ìœ¨(ì—‘ì…€ ë™ì¼): SUM(conv_order_cnt) / COUNT(ticket_id)
    df["conv_rate"] = df.apply(
        lambda r: (r["conv_order_cnt"] / r["ticket_cnt"]) if r["ticket_cnt"] else 0.0, axis=1
    )
    return df

# =========================================================
# 5) KPIìš©(ì„¼í„° ìš”ì•½)ë„ ì§‘ê³„ ê²°ê³¼ì—ì„œ ê³„ì‚°
# =========================================================
def center_summary_from_agg(agg_df: pd.DataFrame) -> pd.DataFrame:
    cs = (
        agg_df.groupby("agent_center", dropna=False)
        .agg(
            ticket_cnt=("ticket_cnt", "sum"),
            conv_order_cnt=("conv_order_cnt", "sum"),
            conv_pay_amount=("conv_pay_amount", "sum"),
        )
        .reset_index()
    )
    cs["conv_rate"] = cs.apply(
        lambda r: (r["conv_order_cnt"] / r["ticket_cnt"]) if r["ticket_cnt"] else 0.0, axis=1
    )
    return cs

# =========================================================
# 6) Raw ë°ì´í„° ë¡œë“œ (ë²„íŠ¼ í´ë¦­ ì‹œì—ë§Œ + ê¸°ë³¸ LIMIT)
# =========================================================
@st.cache_data(ttl=300, show_spinner=True)
def load_raw(date_from, date_to, limit_rows: int, max_bytes_billed: int) -> pd.DataFrame:
    client = get_bq_client()

    sql = f"""
    SELECT
      inbound_ts_kst,
      inbound_date_kst,
      request_ts_kst,
      assigned_ts_kst,

      ticket_id,
      brand_name,
      matched_order_brand,
      agent_center,
      agent_name,
      category_lv1,
      category_lv2,
      category_lv3,
      customer_phone,

      converted_yn,
      first_order_ts_kst,
      conv_order_cnt,
      conv_pay_amount,
      min_leadtime_hours,
      conv_order_nos,
      conv_sellers,
      matched_by,

      `ë§¤ì¹­_í‹°ì¼“ë²ˆí˜¸`,
      `ë§¤ì¹­_ì£¼ë¬¸ìë²ˆí˜¸`,
      `ë§¤ì¹­_ìˆ˜ë ¹ìë²ˆí˜¸`
    FROM `{SOURCE_FQN}`
    WHERE inbound_date_kst >= @date_from
      AND inbound_date_kst <= @date_to
    ORDER BY inbound_date_kst, inbound_ts_kst, ticket_id
    LIMIT @lim
    """

    job_config = bigquery.QueryJobConfig(
        query_parameters=[
            bigquery.ScalarQueryParameter("date_from", "DATE", date_from),
            bigquery.ScalarQueryParameter("date_to", "DATE", date_to),
            bigquery.ScalarQueryParameter("lim", "INT64", int(limit_rows)),
        ],
        maximum_bytes_billed=max_bytes_billed,
    )

    df = client.query(sql, job_config=job_config).to_dataframe(create_bqstorage_client=True)

    for c in ["inbound_ts_kst", "request_ts_kst", "assigned_ts_kst", "first_order_ts_kst"]:
        if c in df.columns:
            df[c] = pd.to_datetime(df[c], errors="coerce")

    if "inbound_date_kst" in df.columns:
        df["inbound_date_kst"] = pd.to_datetime(df["inbound_date_kst"], errors="coerce").dt.date

    for c in ["conv_order_cnt", "conv_pay_amount"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0).astype("int64")

    if "min_leadtime_hours" in df.columns:
        df["min_leadtime_hours"] = pd.to_numeric(df["min_leadtime_hours"], errors="coerce")

    df["agent_center"] = df["agent_center"].fillna("ì—†ìŒ")
    df["agent_name"] = df["agent_name"].fillna("ì—†ìŒ")

    return df

# =========================================================
# 7) í‘œì‹œ í¬ë§·
# =========================================================
def fmt_display(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()

    def _int(x):
        try:
            return f"{int(x):,}"
        except Exception:
            return x

    def _money(x):
        try:
            return f"{int(x):,}"
        except Exception:
            return x

    def _rate(x):
        try:
            return f"{float(x) * 100:.1f}%"
        except Exception:
            return x

    for c in out.columns:
        if "ticket_cnt" in c:
            out[c] = out[c].apply(_int)
        elif "conv_order_cnt" in c:
            out[c] = out[c].apply(_int)
        elif "conv_pay_amount" in c:
            out[c] = out[c].apply(_money)
        elif "conv_rate" in c:
            out[c] = out[c].apply(_rate)
    return out

# =========================================================
# 8) Sidebar
# =========================================================
st.sidebar.header("í•„í„°")
default_from = pd.to_datetime("2026-01-01").date()
default_to = pd.to_datetime("2026-01-31").date()
date_from = st.sidebar.date_input("ì‹œì‘ì¼", value=default_from)
date_to = st.sidebar.date_input("ì¢…ë£Œì¼", value=default_to)

st.sidebar.caption("ì „í™˜ìœ¨ = SUM(conv_order_cnt) / COUNT(ticket_id) (ì—‘ì…€ ë™ì¼)")

st.sidebar.divider()
st.sidebar.header("í”¼ë²— ì„¤ì •")

available_dims = [
    "agent_name",
    "brand_name",
    "category_lv1", "category_lv2", "category_lv3",
    "matched_order_brand",
    "converted_yn",
]

rows = st.sidebar.multiselect("ROWS (ë“œë¦´ë‹¤ìš´)", options=available_dims, default=["agent_name"])

col_candidates = [c for c in available_dims if c not in set(rows)]
col = st.sidebar.selectbox("COLUMNS (ì„ íƒ)", options=["(ì—†ìŒ)"] + col_candidates, index=0)
col = None if col == "(ì—†ìŒ)" else col

min_ticket = st.sidebar.number_input("ìµœì†Œ í‹°ì¼“ìˆ˜(í•„í„°)", min_value=0, value=0, step=10)
sort_key = st.sidebar.selectbox(
    "ì •ë ¬", options=["ticket_cnt", "conv_order_cnt", "conv_pay_amount", "conv_rate"], index=3
)
sort_desc = st.sidebar.checkbox("ë‚´ë¦¼ì°¨ìˆœ", value=True)

st.sidebar.divider()
st.sidebar.header("BigQuery ë¹„ìš© ì•ˆì „ì¥ì¹˜")

max_gb = st.sidebar.slider("ì¿¼ë¦¬ ìµœëŒ€ ìŠ¤ìº” í—ˆìš©(GB)", min_value=0.5, max_value=50.0, value=5.0, step=0.5)
max_bytes_billed = bytes_from_gb(max_gb)

raw_limit = st.sidebar.selectbox(
    "ë¡œìš°ë°ì´í„° ê¸°ë³¸ LIMIT", options=[1000, 5000, 20000, 50000, 100000], index=3
)

# =========================================================
# 9) ì§‘ê³„ ë¡œë“œ
# =========================================================
try:
    agg_df = load_agg(date_from, date_to, rows, col, max_bytes_billed)
except Exception as e:
    st.error(f"í”¼ë²— ì§‘ê³„ ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()

if agg_df.empty:
    st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ê¸°ê°„/í•„í„° í™•ì¸)")
    st.stop()

# =========================================================
# 10) KPI
# =========================================================
center_sum = center_summary_from_agg(agg_df)

total_ticket = int(center_sum["ticket_cnt"].sum())
total_conv_orders = int(center_sum["conv_order_cnt"].sum())
total_pay = int(center_sum["conv_pay_amount"].sum())
rate = (total_conv_orders / total_ticket) if total_ticket else 0.0

k1, k2, k3, k4 = st.columns(4)
k1.metric("ì „ì²´ í‹°ì¼“", f"{total_ticket:,}")
k2.metric("ì „í™˜ ì£¼ë¬¸ê±´ìˆ˜ í•©", f"{total_conv_orders:,}")
k3.metric("ì „í™˜ ë§¤ì¶œ í•©", f"{total_pay:,}")
k4.metric("ì „í™˜ìœ¨(ì£¼ë¬¸ê±´ìˆ˜/í‹°ì¼“)", f"{rate * 100:.1f}%")

st.divider()

# =========================================================
# 11) Tabs
# =========================================================
tab_pivot, tab_raw = st.tabs(["ğŸ“Œ í”¼ë²—", "ğŸ§¾ ë¡œìš°ë°ì´í„°(Left Join ê²°ê³¼)"])

with tab_pivot:
    st.subheader("ì„¼í„° ìš”ì•½(ì†Œê³„)")
    center_sum_sorted = center_sum.sort_values(sort_key, ascending=not sort_desc)
    st.dataframe(fmt_display(center_sum_sorted), use_container_width=True, height=220)

    st.download_button(
        "ì„¼í„° ìš”ì•½ CSV ë‹¤ìš´ë¡œë“œ",
        data=center_sum_sorted.to_csv(index=False).encode("utf-8-sig"),
        file_name="center_summary.csv",
        mime="text/csv",
    )

    st.divider()

    st.subheader("ì„¼í„°ë³„ ìƒì„¸ í”¼ë²—")
    centers = center_sum_sorted["agent_center"].tolist()

    for center in centers:
        sub = agg_df[agg_df["agent_center"] == center].copy()

        c_ticket = int(sub["ticket_cnt"].sum())
        c_conv = int(sub["conv_order_cnt"].sum())
        c_pay = int(sub["conv_pay_amount"].sum())
        c_rate = (c_conv / c_ticket) if c_ticket else 0.0

        header = f"{center}  |  í‹°ì¼“ {c_ticket:,} Â· ì „í™˜ì£¼ë¬¸ {c_conv:,} Â· ë§¤ì¶œ {c_pay:,} Â· ì „í™˜ìœ¨ {c_rate*100:.1f}%"
        with st.expander(header, expanded=(center in ["TCK", "SKMNS", "AI"])):

            if col is not None:
                values = ["ticket_cnt", "conv_order_cnt", "conv_pay_amount", "conv_rate"]
                pv = sub.pivot_table(
                    index=rows,
                    columns=col,
                    values=values,
                    aggfunc="sum",
                    fill_value=0,
                )
                pv.columns = [f"{v} | {c}" for (v, c) in pv.columns]
                pv = pv.reset_index()
            else:
                keep_cols = ["agent_center"] + rows + ["ticket_cnt", "conv_order_cnt", "conv_pay_amount", "conv_rate"]
                pv = sub[keep_cols].copy()

            if min_ticket > 0 and col is None and "ticket_cnt" in pv.columns:
                pv = pv[pv["ticket_cnt"] >= min_ticket]

            if col is None and sort_key in pv.columns:
                pv = pv.sort_values(sort_key, ascending=not sort_desc)

            st.dataframe(fmt_display(pv), use_container_width=True, height=520)

            st.download_button(
                f"{center} í”¼ë²— CSV ë‹¤ìš´ë¡œë“œ",
                data=pv.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"pivot_{center}.csv",
                mime="text/csv",
            )

with tab_raw:
    st.subheader("ë¡œìš°ë°ì´í„° (left join ê²°ê³¼ í™•ì¸ / CSV ë‹¤ìš´ë¡œë“œ)")
    st.caption(
        "âš ï¸ ë¡œìš°ë°ì´í„°ëŠ” ë¹„ìš©/ì†ë„ë¥¼ ìœ„í•´ ë²„íŠ¼ í´ë¦­ ì‹œì—ë§Œ ë¶ˆëŸ¬ì˜¤ë©°, ê¸°ë³¸ LIMITê°€ ê±¸ì–´ë‘ .\n"
        "ì›í•˜ë©´ ì‚¬ì´ë“œë°”ì—ì„œ ë¦¬ë°‹ ì˜¬ë ¤ì„œ ì¡°íšŒê°€ëŠ¥í•¨ \n í•œë‹¬ì¹˜ ì •ë„ëŠ” ë””í´íŠ¸ ì„¸íŒ…ê°’ì—ì„œ ì¡°íšŒí•´ë„ ì¶©ë¶„í•©ë‹ˆë‹¤."
    )

    if "raw_loaded" not in st.session_state:
        st.session_state["raw_loaded"] = False
        st.session_state["raw_df"] = None

    load_btn = st.button("ë¡œìš°ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°", type="primary")

    if load_btn:
        try:
            raw_df = load_raw(date_from, date_to, raw_limit, max_bytes_billed)
            st.session_state["raw_df"] = raw_df
            st.session_state["raw_loaded"] = True
        except Exception as e:
            st.error(f"ë¡œìš°ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            st.stop()

    if not st.session_state["raw_loaded"]:
        st.info("ë²„íŠ¼ì„ ëˆŒëŸ¬ ë¡œìš°ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì„¸ìš”.")
        st.stop()

    raw_df = st.session_state["raw_df"].copy()

    f1, f2, f3, f4 = st.columns(4)

    centers = sorted(raw_df["agent_center"].dropna().unique().tolist())
    agents = sorted(raw_df["agent_name"].dropna().unique().tolist())
    convs = ["O", "X"]
    matched_by_opts = sorted([x for x in raw_df["matched_by"].dropna().unique().tolist()])

    with f1:
        center_sel = st.multiselect("ì„¼í„°", options=centers, default=centers)
    with f2:
        agent_sel = st.multiselect("ìƒë‹´ì‚¬", options=agents, default=agents)
    with f3:
        conv_sel = st.multiselect("ì „í™˜ì—¬ë¶€(converted_yn)", options=convs, default=convs)
    with f4:
        matched_by_sel = st.multiselect("ë§¤ì¹­ê¸°ì¤€(matched_by)", options=matched_by_opts)

    q = st.text_input("ê²€ìƒ‰(ticket_id / ì£¼ë¬¸ë²ˆí˜¸ / ì „í™”ë²ˆí˜¸ / ë¸Œëœë“œ)", value="").strip()

    filtered = raw_df[
        raw_df["agent_center"].isin(center_sel)
        & raw_df["agent_name"].isin(agent_sel)
        & raw_df["converted_yn"].isin(conv_sel)
    ]

    if matched_by_sel:
        filtered = filtered[(filtered["matched_by"].isin(matched_by_sel)) | (filtered["converted_yn"] == "X")]

    if q:
        for c in [
            "ticket_id", "conv_order_nos", "customer_phone", "brand_name", "matched_order_brand",
            "ë§¤ì¹­_í‹°ì¼“ë²ˆí˜¸", "ë§¤ì¹­_ì£¼ë¬¸ìë²ˆí˜¸", "ë§¤ì¹­_ìˆ˜ë ¹ìë²ˆí˜¸",
        ]:
            if c in filtered.columns:
                filtered[c] = filtered[c].astype(str)

        mask = (
            filtered["ticket_id"].str.contains(q, na=False)
            | filtered["conv_order_nos"].str.contains(q, na=False)
            | filtered["customer_phone"].str.contains(q, na=False)
            | filtered["brand_name"].str.contains(q, na=False)
            | filtered["matched_order_brand"].str.contains(q, na=False)
            | filtered["ë§¤ì¹­_í‹°ì¼“ë²ˆí˜¸"].str.contains(q, na=False)
            | filtered["ë§¤ì¹­_ì£¼ë¬¸ìë²ˆí˜¸"].str.contains(q, na=False)
            | filtered["ë§¤ì¹­_ìˆ˜ë ¹ìë²ˆí˜¸"].str.contains(q, na=False)
        )
        filtered = filtered[mask]

    st.write(f"ì¡°íšŒ ê²°ê³¼: {len(filtered):,} rows (LIMIT={raw_limit:,})")

    show_cols = [
        "inbound_date_kst", "inbound_ts_kst",
        "ticket_id", "agent_center", "agent_name",
        "brand_name", "matched_order_brand",
        "category_lv1", "category_lv2", "category_lv3",
        "customer_phone",
        "converted_yn",
        "first_order_ts_kst",
        "conv_order_cnt", "conv_pay_amount", "min_leadtime_hours",
        "conv_order_nos", "conv_sellers",
        "matched_by",
        "ë§¤ì¹­_í‹°ì¼“ë²ˆí˜¸", "ë§¤ì¹­_ì£¼ë¬¸ìë²ˆí˜¸", "ë§¤ì¹­_ìˆ˜ë ¹ìë²ˆí˜¸",
    ]
    show_cols = [c for c in show_cols if c in filtered.columns]

    st.dataframe(filtered[show_cols], use_container_width=True, height=650)

    st.download_button(
        "ë¡œìš°ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ(í•„í„° ë°˜ì˜)",
        data=filtered[show_cols].to_csv(index=False).encode("utf-8-sig"),
        file_name=f"01cnv_raw_{date_from}_{date_to}_limit{raw_limit}.csv",
        mime="text/csv",
    )
